{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torchvision.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(\"efficientnet_v2_s\", num_classes=345, dropout=0.0)\n",
    "model.features[0][0] = nn.Conv2d(1, 24, 3, 2, 1, bias=False)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "state = torch.load(\"./checkpoints/temp-efficientnet_v2_s-QuickDraw\")\n",
    "model.load_state_dict(state[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "x = torch.randn(256, 1, 28, 28, requires_grad=True).to(device)\n",
    "torch_out = model(x)\n",
    "# torch.onnx.export(model, x, \"efficientnet_v2_s_quickdraw.onnx\", export_params=True, do_constant_folding=True, input_names = [\"input\"], output_names = [\"output\"], dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}})\n",
    "# onnx_program = torch.onnx.dynamo_export(model, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_program.save(\"effnetv2squickdraw.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(\"efficientnet_v2_s_quickdraw.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(1, 1, 28, 28).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input length: 1\n",
      "Sample input: (tensor([[[[ 1.7735e+00,  1.0513e-01,  1.0396e+00,  ...,  9.8241e-01,\n",
      "            3.5688e-01, -1.1140e+00],\n",
      "          [-1.0462e+00,  2.4896e-01,  2.0069e+00,  ...,  2.3443e-01,\n",
      "            8.1108e-01,  4.2251e-01],\n",
      "          [ 2.2605e+00,  8.0056e-01, -6.2645e-01,  ..., -7.6775e-01,\n",
      "           -1.9519e+00, -1.0537e+00],\n",
      "          ...,\n",
      "          [-2.2383e+00, -6.9262e-01,  1.6229e-01,  ...,  6.5564e-01,\n",
      "            1.8345e-01, -1.5152e+00],\n",
      "          [-2.8821e-01, -7.1788e-02,  1.4528e+00,  ..., -7.0096e-01,\n",
      "            8.8242e-01,  2.3232e-01],\n",
      "          [-2.0215e-01, -5.9241e-01, -1.9561e+00,  ..., -7.9916e-01,\n",
      "           -1.0904e+00, -4.7240e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.0371e-01, -4.7335e-01,  1.6114e+00,  ..., -5.9548e-02,\n",
      "            7.4131e-02,  5.9113e-01],\n",
      "          [ 6.4886e-01, -1.4591e+00,  1.1717e+00,  ...,  2.6022e-01,\n",
      "           -1.1192e+00, -8.4942e-01],\n",
      "          [ 2.1373e-01,  6.2774e-01, -1.6612e+00,  ..., -7.8231e-01,\n",
      "           -7.9880e-01,  8.0476e-01],\n",
      "          ...,\n",
      "          [-4.3178e-01, -5.6349e-01,  4.5487e-01,  ...,  1.6213e+00,\n",
      "           -4.4222e-01,  1.0836e+00],\n",
      "          [-1.6793e+00, -1.6028e-02,  1.0222e+00,  ..., -1.2311e+00,\n",
      "            7.9656e-01,  6.7802e-02],\n",
      "          [ 9.2858e-02, -5.1235e-01, -1.3521e+00,  ...,  8.2530e-01,\n",
      "            5.1270e-01, -7.2438e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0247e+00,  1.1081e+00, -4.1003e-04,  ...,  8.9854e-01,\n",
      "            8.9049e-01, -1.3716e-01],\n",
      "          [ 8.0033e-01,  3.7458e-01,  1.0136e+00,  ...,  8.0242e-01,\n",
      "            7.7247e-02,  1.4541e+00],\n",
      "          [-3.9127e-01,  1.5042e+00,  1.6855e+00,  ...,  2.3666e-01,\n",
      "            7.2194e-01, -1.1916e+00],\n",
      "          ...,\n",
      "          [ 6.3829e-02, -6.8276e-01, -4.4549e-01,  ..., -7.0581e-01,\n",
      "           -2.5401e-01, -6.2824e-01],\n",
      "          [ 1.8571e+00, -1.1972e+00, -7.1904e-01,  ..., -2.8770e-01,\n",
      "            3.8588e-01, -9.3745e-01],\n",
      "          [ 3.9699e-01,  9.2153e-01,  1.4111e+00,  ..., -8.9801e-01,\n",
      "            2.4903e-01,  3.3999e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 5.9376e-03,  2.2660e-01, -8.8529e-01,  ..., -1.4543e-02,\n",
      "           -1.6566e+00, -3.4975e-01],\n",
      "          [ 4.0194e-02, -1.3776e+00,  3.5980e-01,  ..., -5.7802e-01,\n",
      "            2.3719e-01,  1.7618e-01],\n",
      "          [ 1.3908e+00,  3.7961e-01, -3.9826e-01,  ..., -3.3397e-01,\n",
      "           -1.8771e-01, -4.0243e-01],\n",
      "          ...,\n",
      "          [ 4.4629e-02, -4.1365e-01,  5.6673e-01,  ...,  1.3206e+00,\n",
      "            4.1995e-01, -1.6882e+00],\n",
      "          [-6.4435e-01, -6.4997e-01, -1.6677e+00,  ...,  1.3422e+00,\n",
      "            9.3713e-01,  1.2685e+00],\n",
      "          [-1.5084e+00, -4.9963e-01,  7.5296e-02,  ..., -8.3956e-01,\n",
      "           -3.4938e-01, -1.2688e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.9929e+00,  4.2365e-01, -9.5137e-01,  ..., -8.2382e-01,\n",
      "           -4.9868e-01, -2.3872e-01],\n",
      "          [-7.3648e-01, -1.0220e+00,  9.2373e-01,  ...,  1.7281e-01,\n",
      "            4.1505e-03,  2.2505e+00],\n",
      "          [-1.3977e+00, -2.3536e-01,  1.3798e+00,  ..., -1.2143e+00,\n",
      "            3.6606e-03, -2.8357e-02],\n",
      "          ...,\n",
      "          [-4.3216e-01,  7.9312e-01, -2.2699e-01,  ..., -6.4121e-01,\n",
      "            5.9405e-01,  1.1444e+00],\n",
      "          [ 2.9364e-01,  1.6357e-01, -8.2980e-01,  ..., -7.2978e-01,\n",
      "            2.0927e+00, -5.6940e-02],\n",
      "          [ 4.2668e-01,  2.2014e-02, -1.2468e+00,  ...,  5.1829e-01,\n",
      "           -2.2051e+00,  5.5628e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4307e+00, -2.2112e+00, -6.6654e-01,  ..., -1.8526e+00,\n",
      "            2.2930e-01, -7.0427e-01],\n",
      "          [-3.5110e-01, -6.9134e-01,  1.5067e-01,  ...,  1.0626e+00,\n",
      "            2.4893e-01,  1.1228e+00],\n",
      "          [-1.7463e+00, -2.8202e-01, -8.8578e-02,  ...,  2.0440e-01,\n",
      "           -1.4783e+00,  6.5699e-01],\n",
      "          ...,\n",
      "          [-2.8740e-02, -7.2359e-01,  1.6750e+00,  ...,  2.7362e-01,\n",
      "            6.6763e-01,  1.2679e+00],\n",
      "          [ 1.0004e-01,  1.1316e+00, -2.9982e-01,  ...,  1.9509e+00,\n",
      "            1.2002e+00, -3.9685e-01],\n",
      "          [-8.5981e-01,  2.8919e-01,  2.2650e-01,  ..., -1.5739e+00,\n",
      "            5.3730e-01,  2.8243e-01]]]], requires_grad=True),)\n"
     ]
    }
   ],
   "source": [
    "onnx_input = onnx_program.adapt_torch_inputs_to_onnx(x)\n",
    "print(f\"Input length: {len(onnx_input)}\")\n",
    "print(f\"Sample input: {onnx_input}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session = onnxruntime.InferenceSession(\"efficientnet_v2_s_quickdraw.onnx\", providers=[\"CUDAExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnxruntime_input = {k.name: to_numpy(v) for k, v in zip(ort_session.get_inputs(), onnx_input)}\n",
    "onnxruntime_outputs = ort_session.run(None, onnxruntime_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_session.get_inputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input must be a list of dictionaries or a single numpy array for input 'input'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m onnxruntime_input \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: x}\n\u001b[1;32m----> 2\u001b[0m onnxruntime_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mort_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43monnxruntime_input\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Andrew\\miniforge3\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:220\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[0;32m    218\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input must be a list of dictionaries or a single numpy array for input 'input'."
     ]
    }
   ],
   "source": [
    "onnxruntime_input = {\"input\": x}\n",
    "onnxruntime_outputs = ort_session.run(None, onnxruntime_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_outputs = model(x)\n",
    "torch_outputs = onnx_program.adapt_torch_outputs_to_onnx(torch_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Tensor-likes are not close!\n\nMismatched elements: 4 / 88320 (0.0%)\nGreatest absolute difference: 2.944469451904297e-05 at index (217, 5) (up to 1e-05 allowed)\nGreatest relative difference: 0.01649314910173416 at index (208, 152) (up to 0.001 allowed)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(torch_outputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(onnxruntime_outputs)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m torch_output, onnxruntime_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(torch_outputs, onnxruntime_outputs):\n\u001b[1;32m----> 3\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_close\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43monnxruntime_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPyTorch and ONNX Runtime output matched!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(onnxruntime_outputs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Andrew\\miniforge3\\lib\\site-packages\\torch\\testing\\_comparison.py:1523\u001b[0m, in \u001b[0;36massert_close\u001b[1;34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_layout, check_stride, msg)\u001b[0m\n\u001b[0;32m   1501\u001b[0m error_metas \u001b[38;5;241m=\u001b[39m not_close_error_metas(\n\u001b[0;32m   1502\u001b[0m     actual,\n\u001b[0;32m   1503\u001b[0m     expected,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1518\u001b[0m     msg\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[0;32m   1519\u001b[0m )\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_metas:\n\u001b[0;32m   1522\u001b[0m     \u001b[38;5;66;03m# TODO: compose all metas into one AssertionError\u001b[39;00m\n\u001b[1;32m-> 1523\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_metas[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto_error(msg)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Tensor-likes are not close!\n\nMismatched elements: 4 / 88320 (0.0%)\nGreatest absolute difference: 2.944469451904297e-05 at index (217, 5) (up to 1e-05 allowed)\nGreatest relative difference: 0.01649314910173416 at index (208, 152) (up to 0.001 allowed)"
     ]
    }
   ],
   "source": [
    "assert len(torch_outputs) == len(onnxruntime_outputs)\n",
    "for torch_output, onnxruntime_output in zip(torch_outputs, onnxruntime_outputs):\n",
    "    torch.testing.assert_close(torch_output.to(\"cpu\"), torch.tensor(onnxruntime_output), rtol=1e-3, atol=1e-5)\n",
    "\n",
    "print(\"PyTorch and ONNX Runtime output matched!\")\n",
    "print(f\"Output length: {len(onnxruntime_outputs)}\")\n",
    "print(f\"Sample output: {onnxruntime_outputs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference of Pytorch model used 0.46076011657714844 seconds\n",
      "Inference of ONNX model used 0.11152815818786621 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "device = \"cuda\"\n",
    "model.to(device)\n",
    "x = torch.randn(256, 1, 28, 28, requires_grad=True).to(device)\n",
    "\n",
    "start = time.time()\n",
    "torch_out = model(x)\n",
    "end = time.time()\n",
    "print(f\"Inference of Pytorch model used {end - start} seconds\")\n",
    "\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "start = time.time()\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "end = time.time()\n",
    "print(f\"Inference of ONNX model used {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ -1.7509418 ,  -7.0257072 ,  -6.1707773 , ..., -16.943882  ,\n",
       "         -10.683023  ,   1.3855481 ],\n",
       "        [ -0.64571816,  -3.9192946 ,  -4.384699  , ...,  -8.295189  ,\n",
       "          -7.0409455 ,   1.6498849 ],\n",
       "        [ -2.6629148 ,  -9.015192  ,  -4.5159264 , ..., -19.517633  ,\n",
       "         -13.337657  ,   0.9483351 ],\n",
       "        ...,\n",
       "        [-10.925127  , -18.034628  , -17.231544  , ..., -33.50666   ,\n",
       "         -17.958172  ,  -4.6431284 ],\n",
       "        [ -4.5861526 , -11.174621  ,  -9.48193   , ..., -16.354448  ,\n",
       "          -9.117007  ,   3.5767696 ],\n",
       "        [ -5.615005  , -11.875569  , -11.360513  , ..., -17.924488  ,\n",
       "          -8.923729  ,   3.0314457 ]], dtype=float32)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Tensor-likes are not close!\n\nMismatched elements: 33052 / 88320 (37.4%)\nGreatest absolute difference: 0.11327171325683594 at index (59, 342) (up to 1e-05 allowed)\nGreatest relative difference: 44.576210021972656 at index (72, 86) (up to 0.001 allowed)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_close\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch_out\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mort_outs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Andrew\\miniforge3\\lib\\site-packages\\torch\\testing\\_comparison.py:1523\u001b[0m, in \u001b[0;36massert_close\u001b[1;34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_layout, check_stride, msg)\u001b[0m\n\u001b[0;32m   1501\u001b[0m error_metas \u001b[38;5;241m=\u001b[39m not_close_error_metas(\n\u001b[0;32m   1502\u001b[0m     actual,\n\u001b[0;32m   1503\u001b[0m     expected,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1518\u001b[0m     msg\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[0;32m   1519\u001b[0m )\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_metas:\n\u001b[0;32m   1522\u001b[0m     \u001b[38;5;66;03m# TODO: compose all metas into one AssertionError\u001b[39;00m\n\u001b[1;32m-> 1523\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_metas[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto_error(msg)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Tensor-likes are not close!\n\nMismatched elements: 33052 / 88320 (37.4%)\nGreatest absolute difference: 0.11327171325683594 at index (59, 342) (up to 1e-05 allowed)\nGreatest relative difference: 44.576210021972656 at index (72, 86) (up to 0.001 allowed)"
     ]
    }
   ],
   "source": [
    "torch.testing.assert_close(to_numpy(torch_out), ort_outs[0], rtol=1e-3, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Tensor-likes are not close!\n\nMismatched elements: 91 / 345 (26.4%)\nGreatest absolute difference: 0.021764755249023438 at index (204,) (up to 1e-05 allowed)\nGreatest relative difference: 0.1622679978609085 at index (190,) (up to 0.001 allowed)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m torch_output, onnxruntime_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(torch_out, ort_outs[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_close\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43monnxruntime_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Andrew\\miniforge3\\lib\\site-packages\\torch\\testing\\_comparison.py:1523\u001b[0m, in \u001b[0;36massert_close\u001b[1;34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_layout, check_stride, msg)\u001b[0m\n\u001b[0;32m   1501\u001b[0m error_metas \u001b[38;5;241m=\u001b[39m not_close_error_metas(\n\u001b[0;32m   1502\u001b[0m     actual,\n\u001b[0;32m   1503\u001b[0m     expected,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1518\u001b[0m     msg\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[0;32m   1519\u001b[0m )\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_metas:\n\u001b[0;32m   1522\u001b[0m     \u001b[38;5;66;03m# TODO: compose all metas into one AssertionError\u001b[39;00m\n\u001b[1;32m-> 1523\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_metas[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto_error(msg)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Tensor-likes are not close!\n\nMismatched elements: 91 / 345 (26.4%)\nGreatest absolute difference: 0.021764755249023438 at index (204,) (up to 1e-05 allowed)\nGreatest relative difference: 0.1622679978609085 at index (190,) (up to 0.001 allowed)"
     ]
    }
   ],
   "source": [
    "for torch_output, onnxruntime_output in zip(torch_out, ort_outs[0]):\n",
    "    torch.testing.assert_close(torch_output.to(\"cpu\"), torch.tensor(onnxruntime_output), rtol=1e-3, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPU'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnxruntime.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: ONNX_MODE=cuda\n"
     ]
    }
   ],
   "source": [
    "%env ONNX_MODE=cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "print(onnxruntime.get_available_providers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################\n",
      "########## refreshing ##########\n",
      "################################\n"
     ]
    }
   ],
   "source": [
    "import QuickDraw as Data\n",
    "\n",
    "test = Data.test_dataloader(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "print(ort_session.get_providers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.77%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for images, labels in test:\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(images)}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    preds = np.argmax(ort_outs[0], axis=1)\n",
    "    correct += (preds == labels.numpy()).sum()\n",
    "    total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.77%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "for images, labels in test:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculation for inference\n",
    "        outputs = model(images)\n",
    "    \n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    correct += (preds == labels).sum().item()\n",
    "    total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
