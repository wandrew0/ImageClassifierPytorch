{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from kaggleguy import KaggleGuy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    ")\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KaggleGuy2(28, 47)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "state = torch.load(\"./models/KaggleGuy2-EMNIST_balanced8956\")\n",
    "model.load_state_dict(state[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "emnist = [None] * 47\n",
    "\n",
    "with open(\"./data/EMNIST/emnist_balanced_mapping.txt\") as f:\n",
    "    f = f.read()\n",
    "    for line in f.split(\"\\n\"):\n",
    "        line = line.split()\n",
    "        emnist[int(line[0])] = int(line[1])    \n",
    "\n",
    "def emnist_to_char(label):\n",
    "    return chr(emnist[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " 'a',\n",
       " 'b',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'n',\n",
       " 'q',\n",
       " 'r',\n",
       " 't']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = [chr(i) for i in emnist]\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "x = torch.randn(256, 1, 28, 28, requires_grad=True).to(device)\n",
    "torch_out = model(x)\n",
    "torch.onnx.export(model, x, \"kaggleguy2_emnist_balanced.onnx\", export_params=True, do_constant_folding=True, input_names = [\"input\"], output_names = [\"output\"], dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}})\n",
    "# onnx_program = torch.onnx.dynamo_export(model, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(\"kaggleguy2_emnist_balanced.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(1, 1, 28, 28).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'onnx_program' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m onnx_input \u001b[38;5;241m=\u001b[39m \u001b[43monnx_program\u001b[49m\u001b[38;5;241m.\u001b[39madapt_torch_inputs_to_onnx(x)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(onnx_input)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample input: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00monnx_input\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'onnx_program' is not defined"
     ]
    }
   ],
   "source": [
    "onnx_input = onnx_program.adapt_torch_inputs_to_onnx(x)\n",
    "print(f\"Input length: {len(onnx_input)}\")\n",
    "print(f\"Sample input: {onnx_input}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session = onnxruntime.InferenceSession(\"kaggleguy2_emnist_balanced.onnx\", providers=[\"CUDAExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'onnx_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m onnxruntime_input \u001b[38;5;241m=\u001b[39m {k\u001b[38;5;241m.\u001b[39mname: to_numpy(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(ort_session\u001b[38;5;241m.\u001b[39mget_inputs(), \u001b[43monnx_input\u001b[49m)}\n\u001b[0;32m      2\u001b[0m onnxruntime_outputs \u001b[38;5;241m=\u001b[39m ort_session\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28;01mNone\u001b[39;00m, onnxruntime_input)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'onnx_input' is not defined"
     ]
    }
   ],
   "source": [
    "onnxruntime_input = {k.name: to_numpy(v) for k, v in zip(ort_session.get_inputs(), onnx_input)}\n",
    "onnxruntime_outputs = ort_session.run(None, onnxruntime_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'input'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_session.get_inputs()[0].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnxruntime_input = {\"input\": x}\n",
    "onnxruntime_outputs = ort_session.run(None, onnxruntime_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_outputs = model(x)\n",
    "torch_outputs = onnx_program.adapt_torch_outputs_to_onnx(torch_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch_outputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtorch_outputs\u001b[49m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(onnxruntime_outputs)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m torch_output, onnxruntime_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(torch_outputs, onnxruntime_outputs):\n\u001b[0;32m      3\u001b[0m     torch\u001b[38;5;241m.\u001b[39mtesting\u001b[38;5;241m.\u001b[39massert_close(torch_output\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m), torch\u001b[38;5;241m.\u001b[39mtensor(onnxruntime_output), rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch_outputs' is not defined"
     ]
    }
   ],
   "source": [
    "assert len(torch_outputs) == len(onnxruntime_outputs)\n",
    "for torch_output, onnxruntime_output in zip(torch_outputs, onnxruntime_outputs):\n",
    "    torch.testing.assert_close(torch_output.to(\"cpu\"), torch.tensor(onnxruntime_output), rtol=1e-3, atol=1e-5)\n",
    "\n",
    "print(\"PyTorch and ONNX Runtime output matched!\")\n",
    "print(f\"Output length: {len(onnxruntime_outputs)}\")\n",
    "print(f\"Sample output: {onnxruntime_outputs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference of Pytorch model used 0.42252373695373535 seconds\n",
      "Inference of ONNX model used 0.013001203536987305 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "device = \"cuda\"\n",
    "model.to(device)\n",
    "x = torch.randn(256, 1, 28, 28, requires_grad=True).to(device)\n",
    "\n",
    "start = time.time()\n",
    "torch_out = model(x)\n",
    "end = time.time()\n",
    "print(f\"Inference of Pytorch model used {end - start} seconds\")\n",
    "\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
    "start = time.time()\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "end = time.time()\n",
    "print(f\"Inference of ONNX model used {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-129.12921 , -239.12625 , -116.36777 , ...,  -69.749664,\n",
       "         -133.84784 , -110.82469 ],\n",
       "        [-129.3731  , -338.3047  , -164.02852 , ...,  -81.786446,\n",
       "         -155.29788 , -157.15498 ],\n",
       "        [-106.09598 , -198.57664 ,  -98.421646, ...,  -55.10247 ,\n",
       "         -110.198524,  -95.312675],\n",
       "        ...,\n",
       "        [-104.35375 , -218.34138 , -110.92261 , ...,  -67.35361 ,\n",
       "         -131.36137 , -107.69084 ],\n",
       "        [-117.647446, -249.63028 , -114.04317 , ...,  -61.937504,\n",
       "         -144.511   , -110.879745],\n",
       "        [-132.99767 , -267.40372 , -126.5995  , ...,  -74.62038 ,\n",
       "         -149.04042 , -114.0175  ]], dtype=float32)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Tensor-likes are not close!\n\nMismatched elements: 124 / 12032 (1.0%)\nGreatest absolute difference: 0.055210113525390625 at index (144, 14) (up to 1e-05 allowed)\nGreatest relative difference: 2.9656779766082764 at index (66, 16) (up to 0.001 allowed)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_close\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch_out\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mort_outs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Andrew\\miniforge3\\lib\\site-packages\\torch\\testing\\_comparison.py:1523\u001b[0m, in \u001b[0;36massert_close\u001b[1;34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_layout, check_stride, msg)\u001b[0m\n\u001b[0;32m   1501\u001b[0m error_metas \u001b[38;5;241m=\u001b[39m not_close_error_metas(\n\u001b[0;32m   1502\u001b[0m     actual,\n\u001b[0;32m   1503\u001b[0m     expected,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1518\u001b[0m     msg\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[0;32m   1519\u001b[0m )\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_metas:\n\u001b[0;32m   1522\u001b[0m     \u001b[38;5;66;03m# TODO: compose all metas into one AssertionError\u001b[39;00m\n\u001b[1;32m-> 1523\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_metas[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto_error(msg)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Tensor-likes are not close!\n\nMismatched elements: 124 / 12032 (1.0%)\nGreatest absolute difference: 0.055210113525390625 at index (144, 14) (up to 1e-05 allowed)\nGreatest relative difference: 2.9656779766082764 at index (66, 16) (up to 0.001 allowed)"
     ]
    }
   ],
   "source": [
    "torch.testing.assert_close(to_numpy(torch_out), ort_outs[0], rtol=1e-3, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Tensor-likes are not close!\n\nMismatched elements: 1 / 47 (2.1%)\nGreatest absolute difference: 0.0017535686492919922 at index (16,) (up to 1e-05 allowed)\nGreatest relative difference: 0.0016048387624323368 at index (16,) (up to 0.001 allowed)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m torch_output, onnxruntime_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(torch_out, ort_outs[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtesting\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_close\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43monnxruntime_output\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43matol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Andrew\\miniforge3\\lib\\site-packages\\torch\\testing\\_comparison.py:1523\u001b[0m, in \u001b[0;36massert_close\u001b[1;34m(actual, expected, allow_subclasses, rtol, atol, equal_nan, check_device, check_dtype, check_layout, check_stride, msg)\u001b[0m\n\u001b[0;32m   1501\u001b[0m error_metas \u001b[38;5;241m=\u001b[39m not_close_error_metas(\n\u001b[0;32m   1502\u001b[0m     actual,\n\u001b[0;32m   1503\u001b[0m     expected,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1518\u001b[0m     msg\u001b[38;5;241m=\u001b[39mmsg,\n\u001b[0;32m   1519\u001b[0m )\n\u001b[0;32m   1521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_metas:\n\u001b[0;32m   1522\u001b[0m     \u001b[38;5;66;03m# TODO: compose all metas into one AssertionError\u001b[39;00m\n\u001b[1;32m-> 1523\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_metas[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto_error(msg)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Tensor-likes are not close!\n\nMismatched elements: 1 / 47 (2.1%)\nGreatest absolute difference: 0.0017535686492919922 at index (16,) (up to 1e-05 allowed)\nGreatest relative difference: 0.0016048387624323368 at index (16,) (up to 0.001 allowed)"
     ]
    }
   ],
   "source": [
    "for torch_output, onnxruntime_output in zip(torch_out, ort_outs[0]):\n",
    "    torch.testing.assert_close(torch_output.to(\"cpu\"), torch.tensor(onnxruntime_output), rtol=1e-3, atol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GPU'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onnxruntime.get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: ONNX_MODE=cuda\n"
     ]
    }
   ],
   "source": [
    "%env ONNX_MODE=cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "print(onnxruntime.get_available_providers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import EMNIST as Data\n",
    "\n",
    "test = Data.test_dataloader(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "print(ort_session.get_providers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.76%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for images, labels in test:\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(images)}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    preds = np.argmax(ort_outs[0], axis=1)\n",
    "    correct += (preds == labels.numpy()).sum()\n",
    "    total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.75%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "for images, labels in test:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient calculation for inference\n",
    "        outputs = model(images)\n",
    "    \n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    correct += (preds == labels).sum().item()\n",
    "    total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
